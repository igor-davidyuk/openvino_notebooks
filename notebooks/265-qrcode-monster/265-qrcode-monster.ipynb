{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: diffusers in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (0.21.4)\n",
      "Requirement already satisfied: transformers in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: torch in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting gradio\n",
      "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting qrcode\n",
      "  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m158.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m189.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: Pillow in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from diffusers) (10.1.0)\n",
      "Requirement already satisfied: filelock in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from diffusers) (3.12.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from diffusers) (6.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from diffusers) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.1.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.104.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.3.1-py3-none-any.whl\n",
      "Collecting gradio-client==0.6.1 (from gradio)\n",
      "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio)\n",
      "  Downloading httpx-0.25.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Collecting matplotlib~=3.0 (from gradio)\n",
      "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m208.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 (from gradio)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m539.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m847.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m174.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m406.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m399.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m666.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypng (from qrcode)\n",
      "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m326.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.1)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m219.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m517.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
      "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
      "  Downloading fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m480.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m755.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib~=3.0->gradio)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m901.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from requests->diffusers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from requests->diffusers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from requests->diffusers) (2023.7.22)\n",
      "Collecting click>=7.0 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m242.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting anyio<4.0.0,>=3.7.1 (from fastapi->gradio)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
      "  Downloading httpcore-0.18.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sniffio in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/idavidyu/.virtualenvs/test/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.1.2-py3-none-any.whl (516 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.2/516.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
      "Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0mm\n",
      "\u001b[?25hDownloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m565.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m847.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m97.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m877.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m866.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m99.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m654.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m96.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m794.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m554.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m96.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, pypng, pydub, ffmpy, websockets, tzdata, toolz, semantic-version, qrcode, python-multipart, pyparsing, pydantic-core, orjson, kiwisolver, importlib-resources, h11, fonttools, cycler, contourpy, click, anyio, annotated-types, aiofiles, uvicorn, starlette, pydantic, pandas, matplotlib, httpcore, httpx, fastapi, gradio-client, altair, gradio\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed aiofiles-23.2.1 altair-5.1.2 annotated-types-0.6.0 anyio-3.7.1 click-8.1.7 contourpy-1.1.1 cycler-0.12.1 fastapi-0.104.0 ffmpy-0.3.1 fonttools-4.43.1 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 importlib-resources-6.1.0 kiwisolver-1.4.5 matplotlib-3.8.0 orjson-3.9.9 pandas-2.1.1 pydantic-2.4.2 pydantic-core-2.10.1 pydub-0.25.1 pyparsing-3.1.1 pypng-0.20220715.0 python-multipart-0.0.6 pytz-2023.3.post1 qrcode-7.4.2 semantic-version-2.10.0 starlette-0.27.0 toolz-0.12.0 tzdata-2023.3 uvicorn-0.23.2 websockets-11.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate diffusers transformers torch gradio qrcode\n",
    "%pip install -q \"openvino-dev>=2023.1.0\"\n",
    "\n",
    "\n",
    "# xformers\n",
    "# Pillow\n",
    "# qrcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f59da6ac8be45c28c300f475fc0e659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionControlNetPipeline,\n",
    "    ControlNetModel,\n",
    "    DDIMScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    DEISMultistepScheduler,\n",
    "    HeunDiscreteScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    ")\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"monster-labs/control_v1p_sd15_qrcode_monster\"\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    controlnet=controlnet,\n",
    "    safety_checker=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qrcode\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def create_code(content: str):\n",
    "    qr = qrcode.QRCode(\n",
    "        version=1,\n",
    "        error_correction=qrcode.constants.ERROR_CORRECT_H,\n",
    "        box_size=16,\n",
    "        border=0,\n",
    "    )\n",
    "    qr.add_data(content)\n",
    "    qr.make(fit=True)\n",
    "    img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
    "\n",
    "    # find smallest image size multiple of 256 that can fit qr\n",
    "    offset_min = 8 * 16\n",
    "    w, h = img.size\n",
    "    w = (w + 255 + offset_min) // 256 * 256\n",
    "    h = (h + 255 + offset_min) // 256 * 256\n",
    "    if w > 1024:\n",
    "        raise gr.Error(\"QR code is too large, please use a shorter content\")\n",
    "    bg = Image.new('L', (w, h), 128)\n",
    "\n",
    "    # align on 16px grid\n",
    "    coords = ((w - img.size[0]) // 2 // 16 * 16,\n",
    "              (h - img.size[1]) // 2 // 16 * 16)\n",
    "    bg.paste(img, coords)\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    qr_code_content: str,\n",
    "    prompt: str,\n",
    "    negative_prompt: str,\n",
    "    guidance_scale: float = 10.0,\n",
    "    controlnet_conditioning_scale: float = 2.0,\n",
    "    seed: int = -1,\n",
    "    num_inference_steps = 2,\n",
    "):\n",
    "    if prompt is None or prompt == \"\":\n",
    "        raise gr.Error(\"Prompt is required\")\n",
    "\n",
    "    if qr_code_content is None or qr_code_content == \"\":\n",
    "        raise gr.Error(\"QR Code Content is required\")\n",
    "\n",
    "    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    generator = torch.manual_seed(seed) if seed != -1 else torch.Generator()\n",
    "\n",
    "    print(\"Generating QR Code from content\")\n",
    "    qrcode_image = create_code(qr_code_content)\n",
    "\n",
    "    # hack due to gradio examples\n",
    "    init_image = qrcode_image\n",
    "\n",
    "    out = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        image=qrcode_image,\n",
    "        width=qrcode_image.width,\n",
    "        height=qrcode_image.height,\n",
    "        guidance_scale=float(guidance_scale),\n",
    "        controlnet_conditioning_scale=float(controlnet_conditioning_scale),\n",
    "        generator=generator,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "    )\n",
    "    return out.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating QR Code from content\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ControlNetModel' object has no attribute '_orig_mod'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m controlnet_conditioning_scale \u001b[39m=\u001b[39m \u001b[39m1.5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m seed \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m res \u001b[39m=\u001b[39m inference(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     qr_code_content,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m negative_prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m guidance_scale,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m controlnet_conditioning_scale,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m seed,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "\u001b[1;32m/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# hack due to gradio examples\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m init_image \u001b[39m=\u001b[39m qrcode_image\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m out \u001b[39m=\u001b[39m pipe(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     negative_prompt\u001b[39m=\u001b[39;49mnegative_prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     image\u001b[39m=\u001b[39;49mqrcode_image,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     width\u001b[39m=\u001b[39;49mqrcode_image\u001b[39m.\u001b[39;49mwidth,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     height\u001b[39m=\u001b[39;49mqrcode_image\u001b[39m.\u001b[39;49mheight,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     guidance_scale\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m(guidance_scale),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     controlnet_conditioning_scale\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m(controlnet_conditioning_scale),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     generator\u001b[39m=\u001b[39;49mgenerator,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     num_inference_steps\u001b[39m=\u001b[39;49mnum_inference_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mimages[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/diffusers/pipelines/controlnet/pipeline_controlnet.py:796\u001b[0m, in \u001b[0;36mStableDiffusionControlNetPipeline.__call__\u001b[0;34m(self, prompt, image, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs, controlnet_conditioning_scale, guess_mode, control_guidance_start, control_guidance_end)\u001b[0m\n\u001b[1;32m    791\u001b[0m     control_guidance_start, control_guidance_end \u001b[39m=\u001b[39m mult \u001b[39m*\u001b[39m [control_guidance_start], mult \u001b[39m*\u001b[39m [\n\u001b[1;32m    792\u001b[0m         control_guidance_end\n\u001b[1;32m    793\u001b[0m     ]\n\u001b[1;32m    795\u001b[0m \u001b[39m# 1. Check inputs. Raise error if not correct\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_inputs(\n\u001b[1;32m    797\u001b[0m     prompt,\n\u001b[1;32m    798\u001b[0m     image,\n\u001b[1;32m    799\u001b[0m     callback_steps,\n\u001b[1;32m    800\u001b[0m     negative_prompt,\n\u001b[1;32m    801\u001b[0m     prompt_embeds,\n\u001b[1;32m    802\u001b[0m     negative_prompt_embeds,\n\u001b[1;32m    803\u001b[0m     controlnet_conditioning_scale,\n\u001b[1;32m    804\u001b[0m     control_guidance_start,\n\u001b[1;32m    805\u001b[0m     control_guidance_end,\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    808\u001b[0m \u001b[39m# 2. Define call parameters\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m prompt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(prompt, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/diffusers/pipelines/controlnet/pipeline_controlnet.py:513\u001b[0m, in \u001b[0;36mStableDiffusionControlNetPipeline.check_inputs\u001b[0;34m(self, prompt, image, callback_steps, negative_prompt, prompt_embeds, negative_prompt_embeds, controlnet_conditioning_scale, control_guidance_start, control_guidance_end)\u001b[0m\n\u001b[1;32m    505\u001b[0m is_compiled \u001b[39m=\u001b[39m \u001b[39mhasattr\u001b[39m(F, \u001b[39m\"\u001b[39m\u001b[39mscaled_dot_product_attention\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrolnet, torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39meval_frame\u001b[39m.\u001b[39mOptimizedModule\n\u001b[1;32m    507\u001b[0m )\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    509\u001b[0m     \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrolnet, ControlNetModel)\n\u001b[1;32m    510\u001b[0m     \u001b[39mor\u001b[39;00m is_compiled\n\u001b[1;32m    511\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrolnet\u001b[39m.\u001b[39m_orig_mod, ControlNetModel)\n\u001b[1;32m    512\u001b[0m ):\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrolnet\u001b[39m.\u001b[39;49m_orig_mod)\n\u001b[1;32m    514\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_image(image, prompt, prompt_embeds)\n\u001b[1;32m    515\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    516\u001b[0m     \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrolnet, MultiControlNetModel)\n\u001b[1;32m    517\u001b[0m     \u001b[39mor\u001b[39;00m is_compiled\n\u001b[1;32m    518\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrolnet\u001b[39m.\u001b[39m_orig_mod, MultiControlNetModel)\n\u001b[1;32m    519\u001b[0m ):\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:210\u001b[0m, in \u001b[0;36mModelMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_dict[name]\n\u001b[1;32m    209\u001b[0m \u001b[39m# call PyTorch's https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ControlNetModel' object has no attribute '_orig_mod'"
     ]
    }
   ],
   "source": [
    "qr_code_content = \"Hi OpenVINO\"\n",
    "prompt = \"mountains\"\n",
    "negative_prompt = \"blurry unreal occluded\"\n",
    "guidance_scale = 7\n",
    "controlnet_conditioning_scale = 1.5\n",
    "seed = 42\n",
    "\n",
    "res = inference(\n",
    "    qr_code_content,\n",
    "prompt,\n",
    "negative_prompt,\n",
    "guidance_scale,\n",
    "controlnet_conditioning_scale,\n",
    "seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import openvino as ov\n",
    "import torch\n",
    "\n",
    "def cleanup_torchscript_cache():\n",
    "    \"\"\"\n",
    "    Helper for removing cached model representation\n",
    "    \"\"\"\n",
    "    torch._C._jit_clear_class_registry()\n",
    "    torch.jit._recursive.concrete_type_store = torch.jit._recursive.ConcreteTypeStore()\n",
    "    torch.jit._state._clear_class_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlnet conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControlNet will be loaded from controlnet.xml\n"
     ]
    }
   ],
   "source": [
    "controlnet_ir_path = Path('./controlnet.xml')\n",
    "\n",
    "\n",
    "controlnet_inputs = {\n",
    "    \"sample\": torch.randn((2, 4, 96, 96)),\n",
    "    \"timestep\": torch.tensor(1),\n",
    "    \"encoder_hidden_states\": torch.randn((2,77,768)),\n",
    "    \"controlnet_cond\": torch.randn((2,3,768,768))\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    down_block_res_samples, mid_block_res_sample = controlnet(**controlnet_inputs, return_dict=False)\n",
    "\n",
    "if not controlnet_ir_path.exists():\n",
    "    with torch.no_grad():\n",
    "        controlnet.forward = partial(controlnet.forward, return_dict=False)\n",
    "        ov_model = ov.convert_model(controlnet, example_input=controlnet_inputs)\n",
    "        ov.save_model(ov_model, controlnet_ir_path)\n",
    "        del ov_model\n",
    "        cleanup_torchscript_cache()\n",
    "    print('ControlNet successfully converted to IR')\n",
    "else:\n",
    "    print(f\"ControlNet will be loaded from {controlnet_ir_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text encoder conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_encoder_ir_path = Path('./text_encoder.xml')\n",
    "\n",
    "if not text_encoder_ir_path.exists():\n",
    "    pipe.text_encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        ov_model = ov.convert_model(\n",
    "            pipe.text_encoder,  # model instance\n",
    "            example_input=torch.ones((1, 77), dtype=torch.long),  # inputs for model tracing\n",
    "        )\n",
    "        ov.save_model(ov_model, text_encoder_ir_path)\n",
    "        del ov_model\n",
    "    cleanup_torchscript_cache()\n",
    "    print('Text Encoder successfully converted to IR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet will be loaded from unet.xml\n"
     ]
    }
   ],
   "source": [
    "unet_ir_path = Path('./unet.xml')\n",
    "\n",
    "dtype_mapping = {\n",
    "    torch.float32: ov.Type.f32,\n",
    "    torch.float64: ov.Type.f64,\n",
    "    torch.int32: ov.Type.i32,\n",
    "    torch.int64: ov.Type.i64\n",
    "}\n",
    "\n",
    "def flattenize_inputs(inputs):\n",
    "    flatten_inputs = []\n",
    "    for input_data in inputs:\n",
    "        if input_data is None:\n",
    "            continue\n",
    "        if isinstance(input_data, (list, tuple)):\n",
    "            flatten_inputs.extend(flattenize_inputs(input_data))\n",
    "        else:\n",
    "            flatten_inputs.append(input_data)\n",
    "    return flatten_inputs\n",
    "\n",
    "\n",
    "pipe.unet.eval()\n",
    "unet_inputs = {\n",
    "    \"sample\": torch.randn((2, 4, 96, 96)),\n",
    "    \"timestep\": torch.tensor(1),\n",
    "    \"encoder_hidden_states\": torch.randn((2,77,768)),\n",
    "    \"down_block_additional_residuals\": down_block_res_samples,\n",
    "    \"mid_block_additional_residual\": mid_block_res_sample\n",
    "}\n",
    "\n",
    "if not unet_ir_path.exists():\n",
    "    with torch.no_grad():\n",
    "        ov_model = ov.convert_model(pipe.unet, example_input=unet_inputs)\n",
    "\n",
    "    flatten_inputs = flattenize_inputs(unet_inputs.values())\n",
    "    for input_data, input_tensor in zip(flatten_inputs, ov_model.inputs):\n",
    "        input_tensor.get_node().set_partial_shape(ov.PartialShape(input_data.shape))\n",
    "        input_tensor.get_node().set_element_type(dtype_mapping[input_data.dtype])\n",
    "    ov_model.validate_nodes_and_infer_types()\n",
    "        \n",
    "    ov.save_model(ov_model, unet_ir_path)\n",
    "    del ov_model\n",
    "    cleanup_torchscript_cache()\n",
    "    # del pipe.unet\n",
    "    gc.collect()\n",
    "    print('Unet successfully converted to IR')\n",
    "else:\n",
    "    # del pipe.unet\n",
    "    print(f\"Unet will be loaded from {unet_ir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE decoder conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE decoder will be loaded from vae.xml\n"
     ]
    }
   ],
   "source": [
    "vae_ir_path = Path('./vae.xml')\n",
    "\n",
    "\n",
    "class VAEDecoderWrapper(torch.nn.Module):\n",
    "    def __init__(self, vae):\n",
    "        super().__init__()\n",
    "        vae.eval()\n",
    "        self.vae = vae\n",
    "\n",
    "    def forward(self, latents):\n",
    "        return self.vae.decode(latents)\n",
    "\n",
    "if not vae_ir_path.exists():\n",
    "    vae_decoder = VAEDecoderWrapper(pipe.vae)\n",
    "    latents = torch.zeros((1, 4, 96, 96))\n",
    "\n",
    "    vae_decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        ov_model = ov.convert_model(vae_decoder, example_input=latents)\n",
    "        ov.save_model(ov_model, vae_ir_path)\n",
    "    del ov_model\n",
    "    cleanup_torchscript_cache()\n",
    "    print('VAE decoder successfully converted to IR')\n",
    "else:\n",
    "    print(f\"VAE decoder will be loaded from {vae_ir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72838b4dc38439a819a585429539e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=[d for d in core.available_devices if \"GPU\" not in d] + [\"AUTO\"],\n",
    "    value='AUTO',\n",
    "    description='Device:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb99a42495c247cf9359f9f0f9393c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating QR Code from content\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da80c1b71264ac3888b8000db741eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (12) must match the size of tensor b (96) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mfrom_numpy(result[\u001b[39m0\u001b[39m]), torch\u001b[39m.\u001b[39mfrom_numpy(result[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m pipe\u001b[39m.\u001b[39mcontrolnet \u001b[39m=\u001b[39m ControlNetWrapper(controlnet_ir_path, controlnet\u001b[39m.\u001b[39mconfig, controlnet\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m res \u001b[39m=\u001b[39m inference(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     qr_code_content,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m negative_prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m guidance_scale,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m controlnet_conditioning_scale,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m seed,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m )\n",
      "\u001b[1;32m/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# hack due to gradio examples\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m init_image \u001b[39m=\u001b[39m qrcode_image\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m out \u001b[39m=\u001b[39m pipe(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     negative_prompt\u001b[39m=\u001b[39;49mnegative_prompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     image\u001b[39m=\u001b[39;49mqrcode_image,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     width\u001b[39m=\u001b[39;49mqrcode_image\u001b[39m.\u001b[39;49mwidth,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     height\u001b[39m=\u001b[39;49mqrcode_image\u001b[39m.\u001b[39;49mheight,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     guidance_scale\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m(guidance_scale),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     controlnet_conditioning_scale\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m(controlnet_conditioning_scale),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     generator\u001b[39m=\u001b[39;49mgenerator,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     num_inference_steps\u001b[39m=\u001b[39;49mnum_inference_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mimages[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/diffusers/pipelines/controlnet/pipeline_controlnet.py:967\u001b[0m, in \u001b[0;36mStableDiffusionControlNetPipeline.__call__\u001b[0;34m(self, prompt, image, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs, controlnet_conditioning_scale, guess_mode, control_guidance_start, control_guidance_end)\u001b[0m\n\u001b[1;32m    964\u001b[0m     mid_block_res_sample \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([torch\u001b[39m.\u001b[39mzeros_like(mid_block_res_sample), mid_block_res_sample])\n\u001b[1;32m    966\u001b[0m \u001b[39m# predict the noise residual\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m noise_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munet(\n\u001b[1;32m    968\u001b[0m     latent_model_input,\n\u001b[1;32m    969\u001b[0m     t,\n\u001b[1;32m    970\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mprompt_embeds,\n\u001b[1;32m    971\u001b[0m     cross_attention_kwargs\u001b[39m=\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m    972\u001b[0m     down_block_additional_residuals\u001b[39m=\u001b[39;49mdown_block_res_samples,\n\u001b[1;32m    973\u001b[0m     mid_block_additional_residual\u001b[39m=\u001b[39;49mmid_block_res_sample,\n\u001b[1;32m    974\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    975\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    977\u001b[0m \u001b[39m# perform guidance\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m do_classifier_free_guidance:\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:1005\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         sample \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m down_block_additional_residuals\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n\u001b[1;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m is_controlnet:\n\u001b[0;32m-> 1005\u001b[0m     sample \u001b[39m=\u001b[39m sample \u001b[39m+\u001b[39;49m mid_block_additional_residual\n\u001b[1;32m   1007\u001b[0m \u001b[39m# 5. up\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39mfor\u001b[39;00m i, upsample_block \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup_blocks):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (12) must match the size of tensor b (96) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# Controlnet wrapper\n",
    "from typing import Any\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"monster-labs/control_v1p_sd15_qrcode_monster\"\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    controlnet=controlnet,\n",
    "    safety_checker=None,\n",
    ")\n",
    "\n",
    "class ControlNetWrapper(ControlNetModel):\n",
    "    def __init__(self, ir_path,\n",
    "                 config,\n",
    "                 dtype) -> None:\n",
    "        self.model = core.compile_model(ir_path, device_name=device.value)\n",
    "        self._config = config\n",
    "        self._dtype = dtype\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        return self._config\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self._dtype\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        sample,\n",
    "        timestep,\n",
    "        encoder_hidden_states,\n",
    "        controlnet_cond,\n",
    "        **_\n",
    "    ) -> Any:\n",
    "        result = self.model(sample, timestep,\n",
    "                            encoder_hidden_states,\n",
    "                            controlnet_cond)\n",
    "        return torch.from_numpy(result[0]), torch.from_numpy(result[1])\n",
    "    \n",
    "pipe.controlnet = ControlNetWrapper(controlnet_ir_path, controlnet.config, controlnet.dtype)\n",
    "\n",
    "res = inference(\n",
    "    qr_code_content,\n",
    "prompt,\n",
    "negative_prompt,\n",
    "guidance_scale,\n",
    "controlnet_conditioning_scale,\n",
    "seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception from src/bindings/python/src/pyopenvino/utils/utils.cpp:233:\nPath: 'ControlNetModel(\n  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (time_proj): Timesteps()\n  (time_embedding): TimestepEmbedding(\n    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n    (act): SiLU()\n    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n  )\n  (controlnet_cond_embedding): ControlNetConditioningEmbedding(\n    (conv_in): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (blocks): ModuleList(\n      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n    (conv_out): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (down_blocks): ModuleList(\n    (0): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (3): DownBlock2D(\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n  )\n  (controlnet_down_blocks): ModuleList(\n    (0-3): 4 x Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n    (4-6): 3 x Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n    (7-11): 5 x Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (controlnet_mid_block): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n  (mid_block): UNetMidBlock2DCrossAttn(\n    (attentions): ModuleList(\n      (0): Transformer2DModel(\n        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n        (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        (transformer_blocks): ModuleList(\n          (0): BasicTransformerBlock(\n            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn1): Attention(\n              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn2): Attention(\n              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n              (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (ff): FeedForward(\n              (net): ModuleList(\n                (0): GEGLU(\n                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                )\n                (1): Dropout(p=0.0, inplace=False)\n                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n              )\n            )\n          )\n        )\n        (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (resnets): ModuleList(\n      (0-1): 2 x ResnetBlock2D(\n        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n    )\n  )\n)' does not exist. Please provide valid model's path either as a string, bytes or pathlib.Path. Examples:\n(1) '/home/user/models/model.onnx'\n(2) Path('/home/user/models/model/model.onnx')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb Cell 20\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m input_tensor \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msample\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mrandn((\u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m96\u001b[39m, \u001b[39m96\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimestep\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mtensor(\u001b[39m1\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mencoder_hidden_states\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mrandn((\u001b[39m2\u001b[39m,\u001b[39m77\u001b[39m,\u001b[39m768\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontrolnet_cond\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mrandn((\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m768\u001b[39m,\u001b[39m768\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m }\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m compiled_model \u001b[39m=\u001b[39m ov\u001b[39m.\u001b[39;49mcompile_model(controlnet)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m original_model \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mcontrolnet\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m original_model\u001b[39m.\u001b[39mdecode(torch\u001b[39m.\u001b[39mones((\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m96\u001b[39m, \u001b[39m96\u001b[39m)))\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/openvino/runtime/ie_api.py:610\u001b[0m, in \u001b[0;36mcompile_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compact method to compile model with AUTO plugin.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \n\u001b[1;32m    603\u001b[0m \u001b[39m:param model_path: Path to file with model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m \n\u001b[1;32m    608\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m core \u001b[39m=\u001b[39m Core()\n\u001b[0;32m--> 610\u001b[0m \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49mcompile_model(model_path, \u001b[39m\"\u001b[39;49m\u001b[39mAUTO\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/openvino/runtime/ie_api.py:543\u001b[0m, in \u001b[0;36mCore.compile_model\u001b[0;34m(self, model, device_name, config)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mif\u001b[39;00m device_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m     \u001b[39mreturn\u001b[39;00m CompiledModel(\n\u001b[1;32m    539\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcompile_model(model, {} \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m config),\n\u001b[1;32m    540\u001b[0m     )\n\u001b[1;32m    542\u001b[0m \u001b[39mreturn\u001b[39;00m CompiledModel(\n\u001b[0;32m--> 543\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcompile_model(model, device_name, {} \u001b[39mif\u001b[39;49;00m config \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m config),\n\u001b[1;32m    544\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception from src/bindings/python/src/pyopenvino/utils/utils.cpp:233:\nPath: 'ControlNetModel(\n  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (time_proj): Timesteps()\n  (time_embedding): TimestepEmbedding(\n    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n    (act): SiLU()\n    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n  )\n  (controlnet_cond_embedding): ControlNetConditioningEmbedding(\n    (conv_in): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (blocks): ModuleList(\n      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n    (conv_out): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (down_blocks): ModuleList(\n    (0): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n                (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n                (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (3): DownBlock2D(\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n  )\n  (controlnet_down_blocks): ModuleList(\n    (0-3): 4 x Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n    (4-6): 3 x Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n    (7-11): 5 x Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (controlnet_mid_block): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n  (mid_block): UNetMidBlock2DCrossAttn(\n    (attentions): ModuleList(\n      (0): Transformer2DModel(\n        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n        (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        (transformer_blocks): ModuleList(\n          (0): BasicTransformerBlock(\n            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn1): Attention(\n              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn2): Attention(\n              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n              (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n              (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (ff): FeedForward(\n              (net): ModuleList(\n                (0): GEGLU(\n                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                )\n                (1): Dropout(p=0.0, inplace=False)\n                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n              )\n            )\n          )\n        )\n        (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (resnets): ModuleList(\n      (0-1): 2 x ResnetBlock2D(\n        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n    )\n  )\n)' does not exist. Please provide valid model's path either as a string, bytes or pathlib.Path. Examples:\n(1) '/home/user/models/model.onnx'\n(2) Path('/home/user/models/model/model.onnx')\n"
     ]
    }
   ],
   "source": [
    "input_tensor = {\n",
    "    \"sample\": torch.randn((2, 4, 96, 96)),\n",
    "    \"timestep\": torch.tensor(1),\n",
    "    \"encoder_hidden_states\": torch.randn((2,77,768)),\n",
    "    \"controlnet_cond\": torch.randn((2,3,768,768))\n",
    "}\n",
    "compiled_model = ov.compile_model(controlnet)\n",
    "original_model = pipe.controlnet\n",
    "\n",
    "original_model.decode(torch.ones((1, 4, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Incompatible inputs of type: <class 'method'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22496c79612d31302e3138352e31362e3336227d/home/idavidyu/openvino_notebooks/notebooks/265-qrcode-monster/265-qrcode-monster.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m compiled_model(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/openvino/runtime/ie_api.py:384\u001b[0m, in \u001b[0;36mCompiledModel.__call__\u001b[0;34m(self, inputs, share_inputs, share_outputs, shared_memory)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infer_request \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infer_request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_infer_request()\n\u001b[0;32m--> 384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_request\u001b[39m.\u001b[39;49minfer(\n\u001b[1;32m    385\u001b[0m     inputs,\n\u001b[1;32m    386\u001b[0m     share_inputs\u001b[39m=\u001b[39;49m_deprecated_memory_arg(shared_memory, share_inputs),\n\u001b[1;32m    387\u001b[0m     share_outputs\u001b[39m=\u001b[39;49mshare_outputs,\n\u001b[1;32m    388\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/openvino/runtime/ie_api.py:143\u001b[0m, in \u001b[0;36mInferRequest.infer\u001b[0;34m(self, inputs, share_inputs, share_outputs, shared_memory)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer\u001b[39m(\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     70\u001b[0m     inputs: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     shared_memory: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OVDict:\n\u001b[1;32m     76\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Infers specified input(s) in synchronous mode.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[39m    Blocks all methods of InferRequest while request is running.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m    :rtype: OVDict\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m OVDict(\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39minfer(_data_dispatch(\n\u001b[1;32m    144\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    145\u001b[0m         inputs,\n\u001b[1;32m    146\u001b[0m         is_shared\u001b[39m=\u001b[39;49m_deprecated_memory_arg(shared_memory, share_inputs),\n\u001b[1;32m    147\u001b[0m     ), share_outputs\u001b[39m=\u001b[39mshare_outputs))\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/openvino/runtime/utils/data_helpers/data_dispatcher.py:354\u001b[0m, in \u001b[0;36m_data_dispatch\u001b[0;34m(request, inputs, is_shared)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m {}\n\u001b[0;32m--> 354\u001b[0m \u001b[39mreturn\u001b[39;00m create_shared(inputs, request) \u001b[39mif\u001b[39;00m is_shared \u001b[39melse\u001b[39;00m create_copied(inputs, request)\n",
      "File \u001b[0;32m/usr/lib/python3.10/functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    886\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    887\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 889\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/openvino/runtime/utils/data_helpers/data_dispatcher.py:171\u001b[0m, in \u001b[0;36mcreate_shared\u001b[0;34m(inputs, request)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m value_to_tensor(request\u001b[39m.\u001b[39m_inputs_data, request\u001b[39m=\u001b[39mrequest, is_shared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[39m# Error should be raised if type does not match any dispatchers\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible inputs of type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible inputs of type: <class 'method'>"
     ]
    }
   ],
   "source": [
    "compiled_model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
